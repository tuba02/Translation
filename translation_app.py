import sys
import traceback
import logging
import os
import customtkinter as ctk
import sounddevice as sd
import numpy as np
import wave
import tempfile
import whisper
from openai import OpenAI
from dotenv import load_dotenv

# .env èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.DEBUG)

# ä¾‹å¤–å‡¦ç†
def custom_excepthook(exctype, value, tb):
    logging.error("An error occurred:")
    traceback.print_exception(exctype, value, tb)
    update_text_output(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(value)}\n")

sys.excepthook = custom_excepthook

# ChatGPTäº’æ›APIè¨­å®š
api_key = os.getenv("OPENROUTER_API_KEY")
if not api_key:
    logging.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
else:
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=api_key
    )

# Whisperãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
model = whisper.load_model("base")

# ã‚¢ãƒ—ãƒªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
ctk.set_appearance_mode("system")
ctk.set_default_color_theme("blue")
app = ctk.CTk()
app.title("éŸ³å£°ç¿»è¨³ã‚¢ãƒ—ãƒª")
app.geometry("600x550")

# ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚¨ãƒªã‚¢
text_output = ctk.CTkTextbox(app, height=150, wrap="word")
text_output.pack(pady=10, padx=20, fill="both", expand=True)

# ç¿»è¨³å‡ºåŠ›ã‚¨ãƒªã‚¢
translation_output = ctk.CTkTextbox(app, height=100, wrap="word")
translation_output.pack(pady=10, padx=20, fill="both", expand=True)

# ç¿»è¨³è¨€èªé¸æŠ
language_var = ctk.StringVar(value="ja")

language_frame = ctk.CTkFrame(app)
language_frame.pack(pady=10)

ctk.CTkLabel(language_frame, text="ç¿»è¨³å…ˆ:").pack(side="left", padx=10)

lang_options = {
    "æ—¥æœ¬èª": "ja",
    "è‹±èª": "en",
    "ãƒ‰ã‚¤ãƒ„èª": "de"
}

for label, value in lang_options.items():
    ctk.CTkRadioButton(
        language_frame,
        text=label,
        variable=language_var,
        value=value
    ).pack(side="left", padx=5)

# çŠ¶æ…‹ç®¡ç†
is_recording = False
audio_path = None

def update_text_output(text):
    app.after(0, lambda: text_output.insert("end", text))

def update_translation_output(text):
    app.after(0, lambda: translation_output.insert("end", text))

def record_audio(duration=5):
    global is_recording, audio_path
    logging.info("Recording audio...")
    update_text_output("ğŸ™ï¸ éŒ²éŸ³ä¸­...\n")
    audio = []

    def callback(indata, frames, time, status):
        audio.append(indata.copy())

    try:
        with sd.InputStream(callback=callback, channels=1, samplerate=16000, dtype='int16'):
            sd.sleep(duration * 1000)
    except Exception as e:
        logging.error(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
        update_text_output(f"âŒ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {str(e)}\n")
        return None

    audio_np = np.concatenate(audio, axis=0)
    temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    with wave.open(temp_wav.name, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(16000)
        wf.writeframes(audio_np.tobytes())

    update_text_output("âœ… éŒ²éŸ³å®Œäº†\n")
    audio_path = temp_wav.name
    return temp_wav.name

def transcribe_audio(file_path):
    logging.info(f"Transcribing audio from {file_path}...")
    update_text_output("ğŸ” éŸ³å£°èªè­˜ä¸­...\n")
    try:
        result = model.transcribe(file_path)
        transcription = result['text']
        update_text_output(f"ğŸ“ èªè­˜çµæœ: {transcription}\n")
        return transcription
    except Exception as e:
        logging.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        update_text_output(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}\n")
        return None

def translate_text(text, target_lang):
    logging.info(f"Translating to {target_lang}: {text}")
    update_text_output("ğŸŒ ç¿»è¨³ä¸­...\n")

    if target_lang == "ja":
        prompt = "ä»¥ä¸‹ã®æ–‡ç« ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
    elif target_lang == "en":
        prompt = "Please translate the following text into English."
    elif target_lang == "de":
        prompt = "Bitte Ã¼bersetze den folgenden Text ins Deutsche."
    else:
        prompt = "Please translate the following text."

    try:
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": text}
            ]
        )
        translated = completion.choices[0].message.content
        update_translation_output(f"ğŸ“˜ ç¿»è¨³çµæœ: {translated}\n")
        return translated
    except Exception as e:
        logging.error(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
        update_translation_output(f"âŒ ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)}\n")
        return None

def run_pipeline():
    try:
        logging.info("Running pipeline...")
        update_text_output("å‡¦ç†ä¸­...\n")
        text_output.delete("1.0", "end")
        translation_output.delete("1.0", "end")

        if not is_recording:
            return

        audio_path = record_audio(duration=5)
        if audio_path is None:
            return

        transcription = transcribe_audio(audio_path)
        if transcription is None:
            return

        target_lang = language_var.get()
        translate_text(transcription, target_lang)

    except Exception as e:
        logging.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        update_text_output(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}\n")

def toggle_recording():
    global is_recording
    is_recording = not is_recording
    if is_recording:
        record_btn.configure(text="åœæ­¢")
        run_pipeline()
    else:
        record_btn.configure(text="ğŸ¤ éŒ²éŸ³é–‹å§‹")
        update_text_output("éŒ²éŸ³åœæ­¢ã—ã¾ã—ãŸã€‚\n")

# éŒ²éŸ³ãƒœã‚¿ãƒ³
record_btn = ctk.CTkButton(app, text="ğŸ¤ éŒ²éŸ³é–‹å§‹", command=toggle_recording)
record_btn.pack(pady=20)

# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
try:
    app.mainloop()
except Exception as e:
    logging.error(f"ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ä¸­ã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
